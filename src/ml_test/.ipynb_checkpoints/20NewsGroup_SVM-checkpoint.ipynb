{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ0RS3RIjzm3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mTraceback (most recent call last):\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "\u001b[1;31m    return _run_code(code, main_globals, None,\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "\u001b[1;31m    exec(code, run_globals)\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "\u001b[1;31m    app.launch_new_instance()\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
            "\u001b[1;31m    app.initialize(argv)\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/traitlets/config/application.py\", line 118, in inner\n",
            "\u001b[1;31m    return method(app, *args, **kwargs)\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 707, in initialize\n",
            "\u001b[1;31m    self.init_kernel()\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 555, in init_kernel\n",
            "\u001b[1;31m    kernel = kernel_factory(\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/traitlets/config/configurable.py\", line 583, in instance\n",
            "\u001b[1;31m    inst = cls(*args, **kwargs)\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 154, in __init__\n",
            "\u001b[1;31m    import appnope  # type:ignore[import-untyped]\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/appnope/__init__.py\", line 15, in <module>\n",
            "\u001b[1;31m    from ._nope import *  # noqa\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/site-packages/appnope/_nope.py\", line 9, in <module>\n",
            "\u001b[1;31m    import ctypes\n",
            "\u001b[1;31m  File \"/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/ctypes/__init__.py\", line 7, in <module>\n",
            "\u001b[1;31m    from _ctypes import Union, Structure, Array\n",
            "\u001b[1;31mImportError: dlopen(/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/lib-dynload/_ctypes.cpython-38-darwin.so, 0x0002): Library not loaded: @rpath/libffi.8.dylib\n",
            "\u001b[1;31m  Referenced from: <21773C59-F84B-32F4-AAE6-BB1D44CE57FC> /Users/peter/opt/anaconda3/envs/python385/lib/python3.8/lib-dynload/_ctypes.cpython-38-darwin.so\n",
            "\u001b[1;31m  Reason: tried: '/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/lib-dynload/../../libffi.8.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/Users/peter/opt/anaconda3/envs/python385/lib/python3.8/lib-dynload/../../libffi.8.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/Users/peter/opt/anaconda3/envs/python385/bin/../lib/libffi.8.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/Users/peter/opt/anaconda3/envs/python385/bin/../lib/libffi.8.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/usr/local/lib/libffi.8.dylib' (no such file), '/usr/lib/libffi.8.dylib' (no such file, not in dyld cache). \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from statistics import mean\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import statistics\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-GlFsDPlo_z",
        "outputId": "d8e85f76-491b-4b6e-90c5-cba38f066c2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlcX1pFBDxun",
        "outputId": "9600e2df-8792-44d4-b781-e2a3db05eb73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eW1HF8wnwgG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('20-newsgroups-dataset.csv', names = ['text','category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SoqCJuYvCzez",
        "outputId": "1dce7974-1af3-4e4d-8583-2a515a572990"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-135f8792-f10d-48b6-9ee6-b64f105a2d45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: relova@unixg.ubc.ca (Michael A Relova) S...</td>\n",
              "      <td>comp_os_ms-windows_misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: tdunbar@vtaix.cc.vt.edu (Thomas Dunbar) ...</td>\n",
              "      <td>comp_windows_x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: dus@dusws1.ctd.ornl.gov (Steinert D A) S...</td>\n",
              "      <td>comp_windows_x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: fierkelab@bchm.biochem.duke.edu (Eric Ro...</td>\n",
              "      <td>rec_sport_baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: mangoe@cs.umd.edu (Charley Wingate) Subj...</td>\n",
              "      <td>alt_atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18841</th>\n",
              "      <td>From: rkim@mars.uucp (Richard H.S. Kim) Subjec...</td>\n",
              "      <td>sci_electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18842</th>\n",
              "      <td>From: bgardner@pebbles.es.com (Blaine Gardner)...</td>\n",
              "      <td>rec_motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18843</th>\n",
              "      <td>From: gary@ke4zv.uucp (Gary Coffman) Subject: ...</td>\n",
              "      <td>sci_space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18844</th>\n",
              "      <td>From: asphaug@lpl.arizona.edu (Erik Asphaug x2...</td>\n",
              "      <td>rec_motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18845</th>\n",
              "      <td>From: dsew@troi.cc.rochester.edu (David Sewell...</td>\n",
              "      <td>sci_med</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18846 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-135f8792-f10d-48b6-9ee6-b64f105a2d45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-135f8792-f10d-48b6-9ee6-b64f105a2d45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-135f8792-f10d-48b6-9ee6-b64f105a2d45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "0      From: relova@unixg.ubc.ca (Michael A Relova) S...   \n",
              "1      From: tdunbar@vtaix.cc.vt.edu (Thomas Dunbar) ...   \n",
              "2      From: dus@dusws1.ctd.ornl.gov (Steinert D A) S...   \n",
              "3      From: fierkelab@bchm.biochem.duke.edu (Eric Ro...   \n",
              "4      From: mangoe@cs.umd.edu (Charley Wingate) Subj...   \n",
              "...                                                  ...   \n",
              "18841  From: rkim@mars.uucp (Richard H.S. Kim) Subjec...   \n",
              "18842  From: bgardner@pebbles.es.com (Blaine Gardner)...   \n",
              "18843  From: gary@ke4zv.uucp (Gary Coffman) Subject: ...   \n",
              "18844  From: asphaug@lpl.arizona.edu (Erik Asphaug x2...   \n",
              "18845  From: dsew@troi.cc.rochester.edu (David Sewell...   \n",
              "\n",
              "                      category  \n",
              "0      comp_os_ms-windows_misc  \n",
              "1               comp_windows_x  \n",
              "2               comp_windows_x  \n",
              "3           rec_sport_baseball  \n",
              "4                  alt_atheism  \n",
              "...                        ...  \n",
              "18841          sci_electronics  \n",
              "18842          rec_motorcycles  \n",
              "18843                sci_space  \n",
              "18844          rec_motorcycles  \n",
              "18845                  sci_med  \n",
              "\n",
              "[18846 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTZEObcdnzcX",
        "outputId": "f26cc687-cb40-4d8c-f072-bf8aa7f4c360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['comp_os_ms-windows_misc', 'comp_windows_x', 'rec_sport_baseball',\n",
              "       'alt_atheism', 'sci_crypt', 'rec_motorcycles', 'rec_sport_hockey',\n",
              "       'sci_med', 'comp_sys_ibm_pc_hardware', 'soc_religion_christian',\n",
              "       'sci_electronics', 'talk_religion_misc', 'sci_space',\n",
              "       'talk_politics_misc', 'comp_sys_mac_hardware', 'comp_graphics',\n",
              "       'misc_forsale', 'talk_politics_mideast', 'rec_autos',\n",
              "       'talk_politics_guns'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['category'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Zq85Lsn5Y7",
        "outputId": "ba39609a-0114-4846-bbdf-b9bc85c8f789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total columns at least one Values: \n",
            "Empty DataFrame\n",
            "Columns: [Total, Percent]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# a Function to Calculate the precentage of Missing Values for each Column!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "def missing_values(df):\n",
        "    total = df.isnull().sum().sort_values(ascending = False) # getting the sum of null values and ordering\n",
        "    percent = (df.isnull().sum() / df.isnull().count() * 100 ).sort_values(ascending = False)\n",
        "    df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    print(\"Total columns at least one Values: \")\n",
        "    print (df[~(df['Total'] == 0)]) # Returning values of nulls different of 0\n",
        "\n",
        "    return\n",
        "missing_values(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "148LgiI_JaDy",
        "outputId": "da943e9f-65dd-4afe-ec5f-34eb5c8db22a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "### Start of Text Pre-processing\n",
        "import re\n",
        "import string\n",
        "string.punctuation\n",
        "\n",
        "### 2. To LowerCase\n",
        "\n",
        "df['CleanedText'] = (df.text.apply(lambda x: x.lower()))\n",
        "\n",
        "### 3. Removing Numbers and Special Characters including XXXXXX\n",
        "\n",
        "df['CleanedText'] =  (df.CleanedText.apply(lambda x: re.sub('\\W+', ' ', x)))\n",
        "regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
        "\n",
        "df['CleanedText'] =  (df.CleanedText.apply(lambda x: re.sub(regex, '', x)))\n",
        "df['CleanedText'] =  (df.CleanedText.apply(lambda x: re.sub('xxxx', '', x)))\n",
        "df['CleanedText'] =  (df.CleanedText.apply(lambda x: re.sub('xx', '', x)))\n",
        "\n",
        "### 4. Removing Punctuation\n",
        "\n",
        "def remove_punctuation(x):\n",
        "    punctuationfree=\"\".join([i for i in x if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "\n",
        "df['CleanedText'] =  (df.CleanedText.apply(lambda x: remove_punctuation(x)))\n",
        "\n",
        "### 5. Tokenization\n",
        "#data['TokenizedText'] =  (data.CleanedText.apply(lambda x: re.split('W+',x)))\n",
        "\n",
        "\n",
        "### 6. Removing Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))\n",
        "df['CleanedText'] = df.CleanedText.apply(lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
        "\n",
        " ## TFIDF already tokenizes the text so no need to tokenize it here\n",
        "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "# data2['TokenizedText'] = data2.CleanedText.apply(word_tokenize)\n",
        "\n",
        "\n",
        "### 7. Text Normalization  [Lemmatization] -->better than Stemming since it returns actual words\n",
        "## lemmatization is an intelligent operation that uses dictionaries\n",
        "\n",
        "# Using Spacy\n",
        "# import spaCy's language model\n",
        "# function to lemmatize text\n",
        "\n",
        "lmtzr = WordNetLemmatizer()\n",
        "def lemmatization(texts):   ## Stemming (Pls read the difference)\n",
        "    output = []\n",
        "    for x in texts:\n",
        "        s = [lmtzr.lemmatize(w) for w in df['CleanedText']]\n",
        "        output.append(' '.join(s))\n",
        "    return output\n",
        "df['LemmatizedText'] = lemmatization(df['CleanedText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "KlorJTlBJkpz",
        "outputId": "00c20e4d-c06d-44ec-ff2e-10758bb8e97a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'relova unixg ubc ca michael relova subject winfax files ascii format organization university british columbia lines nntp posting host unixg ubc ca zhao may sparta nmsu edu zhao nmsu edu z zhao writes currently using winfax software receive send fax pcs works pretty well problem received files bit map format take lots hd space told programs pattern recognition raster characters fax files translate ascii code store file ascii format would like tell whether software package translation one find software package public domain version winfax newest version ocr optical character recognition built means take fax ie letter convert ascii one edit document w typing however found ocr comes packaged winfax work well omnipage professional also delrina software winfax ver looking good luck regards zizi'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['CleanedText'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "--bNgNYTOZ9x",
        "outputId": "7e772686-d0c8-4801-f790-086a7953a9d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'relova unixg ubc ca michael relova subject winfax files ascii format organization university british columbia lines nntp posting host unixg ubc ca zhao may sparta nmsu edu zhao nmsu edu z zhao writes currently using winfax software receive send fax pcs works pretty well problem received files bit map format take lots hd space told programs pattern recognition raster characters fax files translate ascii code store file ascii format would like tell whether software package translation one find software package public domain version winfax newest version ocr optical character recognition built means take fax ie letter convert ascii one edit document w typing however found ocr comes packaged winfax work well omnipage professional also delrina software winfax ver looking good luck regards zizi'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['LemmatizedText'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blaD0FBvBy8N"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    Tokenize text and return a non-unique list of tokenized words found in the text.\n",
        "    Normalize to lowercase, strip punctuation, remove stop words, filter non-ascii characters.\n",
        "    Lemmatize the words and lastly drop words of length < 3.\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
        "    nopunct = regex.sub(\" \", text)\n",
        "    words = nopunct.split(' ')\n",
        "    # remove any non ascii\n",
        "    words = [word.encode('ascii', 'ignore').decode('ascii') for word in words]\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    words = [lmtzr.lemmatize(w) for w in words]\n",
        "    #words = [w for w in words if len(w) > 2]\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdvnwOa7lsah"
      },
      "outputs": [],
      "source": [
        "df['tokenized'] = df['text'].str.lower().apply(nltk.word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BmZq6NVlsc7",
        "outputId": "d77fec81-08dd-4ac3-9e77-8862b5604b7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [(From:, NNP), (relova@unixg.ubc.ca, NN), ((Mi...\n",
              "1    [(From:, NNP), (tdunbar@vtaix.cc.vt.edu, NN), ...\n",
              "2    [(From:, NNP), (dus@dusws1.ctd.ornl.gov, NN), ...\n",
              "3    [(From:, NNP), (fierkelab@bchm.biochem.duke.ed...\n",
              "4    [(From:, NNP), (mangoe@cs.umd.edu, NN), ((Char...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tagged_titles = df['text'].str.split().map(nltk.pos_tag)\n",
        "tagged_titles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dr7WQFG3nY5q",
        "outputId": "68ab8901-5a73-426c-942c-2879dcc1abf4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c355d4c-8f4f-4ca0-8d74-971ca2b6a4c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[(From:, NNP), (relova@unixg.ubc.ca, NN), ((Mi...</td>\n",
              "      <td>{'NNP': 41, 'NN': 34, 'VBD': 6, 'NNS': 7, 'IN'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[(From:, NNP), (tdunbar@vtaix.cc.vt.edu, NN), ...</td>\n",
              "      <td>{'NNP': 24, 'NN': 9, 'DT': 3, 'CD': 3, 'VBN': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[(From:, NNP), (dus@dusws1.ctd.ornl.gov, NN), ...</td>\n",
              "      <td>{'NNP': 28, 'NN': 24, 'NNS': 4, 'VBP': 3, 'JJ'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[(From:, NNP), (fierkelab@bchm.biochem.duke.ed...</td>\n",
              "      <td>{'NNP': 56, 'NN': 32, 'TO': 7, 'NNS': 7, 'CD':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[(From:, NNP), (mangoe@cs.umd.edu, NN), ((Char...</td>\n",
              "      <td>{'NNP': 52, 'NN': 65, 'IN': 46, 'CD': 5, 'VBD'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c355d4c-8f4f-4ca0-8d74-971ca2b6a4c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c355d4c-8f4f-4ca0-8d74-971ca2b6a4c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c355d4c-8f4f-4ca0-8d74-971ca2b6a4c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  [(From:, NNP), (relova@unixg.ubc.ca, NN), ((Mi...   \n",
              "1  [(From:, NNP), (tdunbar@vtaix.cc.vt.edu, NN), ...   \n",
              "2  [(From:, NNP), (dus@dusws1.ctd.ornl.gov, NN), ...   \n",
              "3  [(From:, NNP), (fierkelab@bchm.biochem.duke.ed...   \n",
              "4  [(From:, NNP), (mangoe@cs.umd.edu, NN), ((Char...   \n",
              "\n",
              "                                          tag_counts  \n",
              "0  {'NNP': 41, 'NN': 34, 'VBD': 6, 'NNS': 7, 'IN'...  \n",
              "1  {'NNP': 24, 'NN': 9, 'DT': 3, 'CD': 3, 'VBN': ...  \n",
              "2  {'NNP': 28, 'NN': 24, 'NNS': 4, 'VBP': 3, 'JJ'...  \n",
              "3  {'NNP': 56, 'NN': 32, 'TO': 7, 'NNS': 7, 'CD':...  \n",
              "4  {'NNP': 52, 'NN': 65, 'IN': 46, 'CD': 5, 'VBD'...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tagged_titles = pd.DataFrame(tagged_titles)\n",
        "tagged_titles['tag_counts'] = tagged_titles['text'].map(count_tags)\n",
        "tagged_titles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNYDhuiQmFKx"
      },
      "outputs": [],
      "source": [
        "def count_tags(title_with_tags):\n",
        "    tag_count = {}\n",
        "    for word, tag in title_with_tags:\n",
        "        if tag in tag_count:\n",
        "            tag_count[tag] += 1\n",
        "        else:\n",
        "            tag_count[tag] = 1\n",
        "    return(tag_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syiWx0sjmKsN"
      },
      "outputs": [],
      "source": [
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za0b6zB8mP1d"
      },
      "outputs": [],
      "source": [
        "# list of part-of-speech tags used in the Penn Treebank Project:\n",
        "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
        "#** For iplot to work in colab --**\n",
        "import cufflinks as cf\n",
        "cf.go_offline()\n",
        "cf.set_config_file(offline=False, world_readable=True)\n",
        "configure_plotly_browser_state()\n",
        "tag_set = list(set([tag for tags in tagged_titles['tag_counts'] for tag in tags ]))\n",
        "for tag in tag_set:\n",
        "    tagged_titles[tag] = tagged_titles['tag_counts'].map(lambda x: x.get(tag, 0))\n",
        "title = 'Frequency of POS Tags in IT Support Tickets Dataset'\n",
        "tagged_titles[tag_set].sum().sort_values(ascending=False).iplot(kind='bar', title=title, xTitle= 'POS', yTitle='count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L51LbE116DHw"
      },
      "source": [
        "**https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdCqmx4DmWjN"
      },
      "outputs": [],
      "source": [
        "inculuded_tags = ['NN','NNS','JJ','VB','VBP','VBZ','VBN','VBG','VBD','FW','NNPS']\n",
        "df['POSText'] = df['tokenized'].apply(lambda x: \" \".join([token for token,pos in nltk.pos_tag(x) if pos in inculuded_tags]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5sailtNkhbW"
      },
      "outputs": [],
      "source": [
        "# split the dataset into the training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['CleanedText']\n",
        "y = df['category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIO4yGvRIU8t"
      },
      "outputs": [],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNoY1ku_kor5"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range = (1,3), sublinear_tf= True, use_idf=True)\n",
        "X_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvwRbHMzkr4U",
        "outputId": "1d74b763-c04c-4fd5-cfd1-85e47a7e297c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy for SVM : 0.8914043155288291\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt_atheism       0.88      0.88      0.88       230\n",
            "           comp_graphics       0.80      0.85      0.82       284\n",
            " comp_os_ms-windows_misc       0.83      0.83      0.83       290\n",
            "comp_sys_ibm_pc_hardware       0.77      0.77      0.77       290\n",
            "   comp_sys_mac_hardware       0.85      0.84      0.84       294\n",
            "          comp_windows_x       0.87      0.89      0.88       300\n",
            "            misc_forsale       0.82      0.87      0.84       304\n",
            "               rec_autos       0.89      0.91      0.90       314\n",
            "         rec_motorcycles       0.96      0.96      0.96       304\n",
            "      rec_sport_baseball       0.96      0.91      0.93       297\n",
            "        rec_sport_hockey       0.92      0.97      0.95       315\n",
            "               sci_crypt       0.97      0.97      0.97       313\n",
            "         sci_electronics       0.88      0.78      0.83       286\n",
            "                 sci_med       0.90      0.91      0.91       301\n",
            "               sci_space       0.94      0.94      0.94       287\n",
            "  soc_religion_christian       0.92      0.96      0.94       274\n",
            "      talk_politics_guns       0.90      0.96      0.93       257\n",
            "   talk_politics_mideast       0.96      0.99      0.98       294\n",
            "      talk_politics_misc       0.94      0.84      0.89       227\n",
            "      talk_religion_misc       0.87      0.73      0.79       193\n",
            "\n",
            "                accuracy                           0.89      5654\n",
            "               macro avg       0.89      0.89      0.89      5654\n",
            "            weighted avg       0.89      0.89      0.89      5654\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import model_selection, naive_bayes, svm, metrics\n",
        "svm = LinearSVC()\n",
        "lr = LogisticRegression()\n",
        "\n",
        "clf = svm.fit(X_tfidf, y_train)\n",
        "#y_pred =svm.predict(X_test_tfidf)\n",
        "y_pred = model_selection.cross_val_predict(svm, X_test_tfidf, y_test, cv = 10)\n",
        "print(\"\\n\\nAccuracy for SVM :\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "nHF27qWqEzwv",
        "outputId": "d0e1e997-8b08-495e-89df-63fae6d720da"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a43f30a6c39c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                            scoring='f1')\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    671\u001b[0m             raise ValueError(\n\u001b[1;32m    672\u001b[0m                 \u001b[0;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0;34m\" number of members in each class.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             )\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
          ]
        }
      ],
      "source": [
        "svm_classifier = LinearSVC()\n",
        "\n",
        "parameter_grid = {'class_weight': [None, 'balanced'],\n",
        "                  'C': [1, 5, 10]}\n",
        "\n",
        "cross_validation = StratifiedKFold()\n",
        "\n",
        "grid_search = GridSearchCV(svm_classifier,\n",
        "                           param_grid=parameter_grid,\n",
        "                           cv=cross_validation,\n",
        "                           scoring='f1')\n",
        "\n",
        "grid_search.fit(X_tfidf, X_train)\n",
        "\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))\n",
        "\n",
        "grid_search.best_estimator_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
